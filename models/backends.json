[
  {
    "backend_id": "nvidia-h100-us-east-1a",
    "chip_type": "NVIDIA H100",
    "latency_ms": 55,
    "cost_per_token": 0.000025,
    "region": "us-east-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus", "gemini-pro", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "gdpr", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 32000,
    "current_load": 65.0,
    "estimated_queue_time_ms": 25
  },
  {
    "backend_id": "nvidia-h100-us-east-1b",
    "chip_type": "NVIDIA H100",
    "latency_ms": 58,
    "cost_per_token": 0.000025,
    "region": "us-east-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus", "gemini-pro", "mistral-large", "mixtral-8x7b"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 32000,
    "current_load": 78.0,
    "estimated_queue_time_ms": 45
  },
  {
    "backend_id": "nvidia-a100-us-west-2a",
    "chip_type": "NVIDIA A100",
    "latency_ms": 75,
    "cost_per_token": 0.000018,
    "region": "us-west-2",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-sonnet", "gemini-pro", "mixtral-8x7b"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 24000,
    "current_load": 78.0,
    "estimated_queue_time_ms": 45
  },
  {
    "backend_id": "tpu-v5p-us-central1a",
    "chip_type": "Google TPU v5p",
    "latency_ms": 48,
    "cost_per_token": 0.000022,
    "region": "us-central1",
    "supported_models": ["gemini-pro", "gemini-flash", "llama-3-70b", "claude-3-sonnet"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "us-data-residency"],
    "max_token_size": 16000,
    "current_load": 55.0,
    "estimated_queue_time_ms": 15
  },
  {
    "backend_id": "groq-lpu-us-east-1a",
    "chip_type": "Groq LPU",
    "latency_ms": 12,
    "cost_per_token": 0.000032,
    "region": "us-east-1",
    "supported_models": ["llama-3-70b", "llama-3-8b", "gemma-7b", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 12000,
    "current_load": 40.0,
    "estimated_queue_time_ms": 5
  },
  {
    "backend_id": "groq-lpu-us-west-2a",
    "chip_type": "Groq LPU",
    "latency_ms": 13,
    "cost_per_token": 0.000032,
    "region": "us-west-2",
    "supported_models": ["llama-3-70b", "llama-3-8b", "gemma-7b", "mistral-large", "mixtral-8x7b"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 12000,
    "current_load": 32.0,
    "estimated_queue_time_ms": 8
  },
  {
    "backend_id": "cerebras-us-west-1a",
    "chip_type": "Cerebras CS-2",
    "latency_ms": 28,
    "cost_per_token": 0.000028,
    "region": "us-west-1",
    "supported_models": ["claude-3-opus", "claude-3-sonnet", "cerebras-lm"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 20000,
    "current_load": 30.0,
    "estimated_queue_time_ms": 10
  },
  {
    "backend_id": "cerebras-us-east-1a",
    "chip_type": "Cerebras CS-2",
    "latency_ms": 29,
    "cost_per_token": 0.000028,
    "region": "us-east-1",
    "supported_models": ["claude-3-opus", "claude-3-sonnet", "cerebras-lm", "llama-3-70b"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 20000,
    "current_load": 45.0,
    "estimated_queue_time_ms": 17
  },
  {
    "backend_id": "nvidia-h100-eu-west-1a",
    "chip_type": "NVIDIA H100",
    "latency_ms": 60,
    "cost_per_token": 0.000028,
    "region": "eu-west-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 32000,
    "current_load": 72.0,
    "estimated_queue_time_ms": 35
  },
  {
    "backend_id": "nvidia-a100-eu-central-1a",
    "chip_type": "NVIDIA A100",
    "latency_ms": 80,
    "cost_per_token": 0.000020,
    "region": "eu-central-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-sonnet", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 24000,
    "current_load": 60.0,
    "estimated_queue_time_ms": 25
  },
  {
    "backend_id": "tpu-v5p-eu-west-1a",
    "chip_type": "Google TPU v5p",
    "latency_ms": 50,
    "cost_per_token": 0.000024,
    "region": "eu-west-1",
    "supported_models": ["gemini-pro", "gemini-flash", "llama-3-70b"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 16000,
    "current_load": 45.0,
    "estimated_queue_time_ms": 12
  },
  {
    "backend_id": "nvidia-h100-ap-northeast-1a",
    "chip_type": "NVIDIA H100",
    "latency_ms": 68,
    "cost_per_token": 0.000030,
    "region": "ap-northeast-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus"],
    "status": "healthy",
    "compliance_tags": ["apac-compliance"],
    "max_token_size": 32000,
    "current_load": 55.0,
    "estimated_queue_time_ms": 20
  },
  {
    "backend_id": "nvidia-a100-ap-southeast-1a",
    "chip_type": "NVIDIA A100",
    "latency_ms": 85,
    "cost_per_token": 0.000022,
    "region": "ap-southeast-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-sonnet"],
    "status": "healthy",
    "compliance_tags": ["apac-compliance"],
    "max_token_size": 24000,
    "current_load": 70.0,
    "estimated_queue_time_ms": 30
  },
  {
    "backend_id": "inferentia-2-us-east-1a",
    "chip_type": "AWS Inferentia 2",
    "latency_ms": 95,
    "cost_per_token": 0.000012,
    "region": "us-east-1",
    "supported_models": ["llama-3-8b", "gemma-7b", "mistral-medium"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 8000,
    "current_load": 25.0,
    "estimated_queue_time_ms": 5
  },
  {
    "backend_id": "azure-maia-us-east-1a",
    "chip_type": "Azure Maia 100",
    "latency_ms": 52,
    "cost_per_token": 0.000026,
    "region": "us-east-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus", "azure-models"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "gdpr", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 30000,
    "current_load": 45.0,
    "estimated_queue_time_ms": 15
  },
  {
    "backend_id": "cerebras-eu-central-1a",
    "chip_type": "Cerebras CS-2",
    "latency_ms": 36,
    "cost_per_token": 0.000029,
    "region": "eu-central-1",
    "supported_models": ["claude-3-opus", "claude-3-sonnet", "cerebras-lm"],
    "status": "degraded",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 20000,
    "current_load": 80.0,
    "estimated_queue_time_ms": 120
  },
  {
    "backend_id": "cerebras-eu-west-1a",
    "chip_type": "Cerebras CS-2",
    "latency_ms": 31,
    "cost_per_token": 0.000029,
    "region": "eu-west-1",
    "supported_models": ["claude-3-opus", "claude-3-sonnet", "cerebras-lm", "llama-3-70b"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 20000,
    "current_load": 45.0,
    "estimated_queue_time_ms": 14
  },
  {
    "backend_id": "sambanova-us-west-2a",
    "chip_type": "SambaNova",
    "latency_ms": 42,
    "cost_per_token": 0.000027,
    "region": "us-west-2",
    "supported_models": ["gpt-4", "llama-3-70b", "sambanova-models"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 22000,
    "current_load": 50.0,
    "estimated_queue_time_ms": 18
  },
  {
    "backend_id": "sambanova-eu-west-1a",
    "chip_type": "SambaNova",
    "latency_ms": 45,
    "cost_per_token": 0.000028,
    "region": "eu-west-1",
    "supported_models": ["gpt-4", "llama-3-70b", "sambanova-models"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 22000,
    "current_load": 38.0,
    "estimated_queue_time_ms": 12
  },
  {
    "backend_id": "gaudi2-us-east-1a",
    "chip_type": "Intel Gaudi 2",
    "latency_ms": 85,
    "cost_per_token": 0.000015,
    "region": "us-east-1",
    "supported_models": ["llama-3-8b", "gemma-7b", "mistral-medium", "intel-lm"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 10000,
    "current_load": 35.0,
    "estimated_queue_time_ms": 8
  },
  {
    "backend_id": "nvidia-l40s-us-east-1a",
    "chip_type": "NVIDIA L40S",
    "latency_ms": 65,
    "cost_per_token": 0.000019,
    "region": "us-east-1",
    "supported_models": ["llama-3-70b", "mixtral-8x7b", "mistral-large", "gemini-pro"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 28000,
    "current_load": 62.0,
    "estimated_queue_time_ms": 22
  },
  {
    "backend_id": "nvidia-l40s-eu-west-1a",
    "chip_type": "NVIDIA L40S",
    "latency_ms": 70,
    "cost_per_token": 0.000020,
    "region": "eu-west-1",
    "supported_models": ["llama-3-70b", "mixtral-8x7b", "mistral-large", "gemini-pro"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 28000,
    "current_load": 48.0,
    "estimated_queue_time_ms": 16
  },
  {
    "backend_id": "google-tpu-v4-us-central1a",
    "chip_type": "Google TPU v4",
    "latency_ms": 55,
    "cost_per_token": 0.000018,
    "region": "us-central1",
    "supported_models": ["gemini-pro", "gemini-flash", "claude-3-haiku", "googleai-palm"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "us-data-residency"],
    "max_token_size": 12000,
    "current_load": 67.0,
    "estimated_queue_time_ms": 28
  },
  {
    "backend_id": "nvidia-h100-me-south-1a",
    "chip_type": "NVIDIA H100",
    "latency_ms": 72,
    "cost_per_token": 0.000028,
    "region": "me-south-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["me-data-residency"],
    "max_token_size": 32000,
    "current_load": 40.0,
    "estimated_queue_time_ms": 12
  },
  {
    "backend_id": "nvidia-a100-sa-east-1a",
    "chip_type": "NVIDIA A100",
    "latency_ms": 90,
    "cost_per_token": 0.000021,
    "region": "sa-east-1",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-sonnet", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["sa-data-residency"],
    "max_token_size": 24000,
    "current_load": 32.0,
    "estimated_queue_time_ms": 10
  },
  {
    "backend_id": "cerebras-ap-northeast-1a",
    "chip_type": "Cerebras CS-2",
    "latency_ms": 38,
    "cost_per_token": 0.000030,
    "region": "ap-northeast-1",
    "supported_models": ["claude-3-opus", "claude-3-sonnet", "cerebras-lm", "llama-3-70b"],
    "status": "healthy",
    "compliance_tags": ["apac-compliance", "japan-data-residency"],
    "max_token_size": 20000,
    "current_load": 58.0,
    "estimated_queue_time_ms": 22
  },
  {
    "backend_id": "groq-lpu-ap-southeast-1a",
    "chip_type": "Groq LPU",
    "latency_ms": 16,
    "cost_per_token": 0.000033,
    "region": "ap-southeast-1",
    "supported_models": ["llama-3-70b", "llama-3-8b", "gemma-7b", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["apac-compliance", "sg-data-residency"],
    "max_token_size": 12000,
    "current_load": 25.0,
    "estimated_queue_time_ms": 4
  },
  {
    "backend_id": "graphcore-ipu-eu-central-1a",
    "chip_type": "Graphcore IPU",
    "latency_ms": 62,
    "cost_per_token": 0.000018,
    "region": "eu-central-1",
    "supported_models": ["llama-3-8b", "gemma-7b", "mistral-medium", "graphcore-lm"],
    "status": "healthy",
    "compliance_tags": ["gdpr", "eu-data-residency"],
    "max_token_size": 8000,
    "current_load": 42.0,
    "estimated_queue_time_ms": 15
  },
  {
    "backend_id": "habana-gaudi2-us-west-1a",
    "chip_type": "Intel Gaudi 2",
    "latency_ms": 78,
    "cost_per_token": 0.000016,
    "region": "us-west-1",
    "supported_models": ["llama-3-8b", "gemma-7b", "mistral-medium", "intel-lm"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency"],
    "max_token_size": 10000,
    "current_load": 30.0,
    "estimated_queue_time_ms": 6
  },
  {
    "backend_id": "nvidia-h200-us-east-2a",
    "chip_type": "NVIDIA H200",
    "latency_ms": 42,
    "cost_per_token": 0.000035,
    "region": "us-east-2",
    "supported_models": ["gpt-4", "llama-3-70b", "claude-3-opus", "gemini-pro", "mistral-large"],
    "status": "healthy",
    "compliance_tags": ["hipaa", "sox", "us-data-residency", "fedramp"],
    "max_token_size": 65536,
    "current_load": 82.0,
    "estimated_queue_time_ms": 50
  }
]